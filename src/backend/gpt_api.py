import openai
from openai import OpenAIError, BadRequestError 
import json
import csv
import os
import requests
from PIL import Image
from io import BytesIO
import pytesseract
from time import sleep
from gpt_prompt import build_summary_prompt

# âœ… ìµœì‹  ë°©ì‹: OpenAI client ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# âœ… GPT ìš”ì•½ ìƒì„± í•¨ìˆ˜ (ë‹¨ê±´)
def generate_summary(performance):
    prompt = build_summary_prompt(performance)

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content
    
    except BadRequestError as e:
        print(f"[ìš”ì²­ ì˜¤ë¥˜] {performance.get('mt20id')}: {e}")
        return "ìš”ì²­ ì˜¤ë¥˜ë¡œ ìš”ì•½ ì‹¤íŒ¨"
    
    except OpenAIError as e:
        print(f"[GPT ì˜¤ë¥˜] {performance.get('mt20id')}: {e}")
        return "GPT ì˜¤ë¥˜ ë°œìƒ"
    
    except Exception as e:
        print(f"[ê¸°íƒ€ ì˜¤ë¥˜] {performance.get('mt20id')}: {e}")
        return "ì˜¤ë¥˜ ë°œìƒ"

# âœ… ë‹¨ê±´ í…ŒìŠ¤íŠ¸ìš©
def process_and_save(json_path, output_csv):
    with open(json_path, encoding="utf-8") as f:
        data = json.load(f)

    summaries = []
    for i, item in enumerate(data[:3]):
        print(f"{i+1}/{len(data)} ì²˜ë¦¬ ì¤‘: {item['prfnm']}")
        summary = generate_summary(item)
        summaries.append({"ê³µì—° ID": item["mt20id"], "ê³µì—° ìš”ì•½": summary})
        sleep(2)

    with open(output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["ê³µì—° ID", "ê³µì—° ìš”ì•½"])
        writer.writeheader()
        writer.writerows(summaries)

    print(f"\nâœ… ë‹¨ê±´ ìš”ì•½ ì €ì¥ ì™„ë£Œ â†’ {output_csv}")

# âœ… ë°°ì¹˜ ì²˜ë¦¬ìš©
def process_and_save_batch(json_path, output_csv, chunk_size=10):

    def chunk_list(data, chunk_size):
        for i in range(0, len(data), chunk_size):
            yield data[i:i + chunk_size]

    def parse_gpt_table(text):
        rows = []
        for line in text.splitlines():
            if line.startswith("|") and not any(sub in line for sub in ["| ê³µì—° ID", "|--------"]):
                parts = [col.strip() for col in line.strip().split("|")[1:-1]]
                if len(parts) == 2:
                    rows.append({"ê³µì—° ID": parts[0], "ê³µì—° ìš”ì•½": parts[1]})
        return rows

    with open(json_path, encoding="utf-8") as f:
        data = json.load(f)

    all_rows = []
    for i, chunk in enumerate(chunk_list(data, chunk_size)):
        print(f"\nğŸ§  GPT ìš”ì²­ {i+1}ì°¨ (ì´ {len(chunk)}ê°œ)")
        prompts = []
        for perf in chunk:
            prompts.append(build_summary_prompt(perf))

        combined_prompt = "\n\n---\n\n".join(prompts)

        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": combined_prompt}],
                temperature=0.7
            )
            gpt_output = response.choices[0].message.content
            parsed_rows = parse_gpt_table(gpt_output)
            all_rows.extend(parsed_rows)
            print(f"âœ… ìš”ì•½ {len(parsed_rows)}ê°œ ì™„ë£Œ")
            
        except BadRequestError as e:
            print(f"[ìš”ì²­ ì˜¤ë¥˜ - ë°°ì¹˜ {i+1}] {e}")
        except OpenAIError as e:
            print(f"[GPT ì˜¤ë¥˜ - ë°°ì¹˜ {i+1}] {e}")
        except Exception as e:
            print(f"[ê¸°íƒ€ ì˜¤ë¥˜ - ë°°ì¹˜ {i+1}] {e}")

        sleep(2)

    with open(output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["ê³µì—° ID", "ê³µì—° ìš”ì•½"])
        writer.writeheader()
        writer.writerows(all_rows)

    print(f"\nâœ… ëª¨ë“  ë°°ì¹˜ ìš”ì•½ ì €ì¥ ì™„ë£Œ â†’ {output_csv}")
