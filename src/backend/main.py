import os
from datetime import datetime, timedelta
from kopis_json_for_gpt import collect_unique_ids, build_performance_dataset
from utils import log, load_existing_ids, save_existing_ids, save_json

BASE_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.join(BASE_DIR, "data")
EXISTING_IDS_PATH = os.path.join(DATA_DIR, "existing_ids.json")
LOG_FILE_PATH = os.path.join(DATA_DIR, "log.txt")


def main(start_date: str, end_date: str):
    
    # ë¡œê·¸ ì´ˆê¸°í™”
    os.makedirs(DATA_DIR, exist_ok=True)
    with open(LOG_FILE_PATH, "w", encoding="utf-8") as f:
        f.write("[ğŸš€ KOPIS ê³µì—° ìˆ˜ì§‘ ë¡œê·¸ ì‹œì‘]\n")
        f.write(f"ì‹œì‘ì¼: {start_date}, ì¢…ë£Œì¼: {end_date}\n")
        f.write("========================================\n")   

    log("ğŸ¬ ê³µì—° ID ìˆ˜ì§‘ ì‹œì‘...")
    new_ids = collect_unique_ids(start_date, end_date)

    log("\nğŸ“ ê¸°ì¡´ ID ë¡œë”© ì¤‘...")
    existing_ids = load_existing_ids(EXISTING_IDS_PATH)

    log(f"ğŸ” ê¸°ì¡´: {len(existing_ids)}ê°œ, ì´ë²ˆ ìˆ˜ì§‘: {len(new_ids)}ê°œ")
    diff_ids = new_ids - existing_ids
    log(f"âœ¨ ìƒˆë¡­ê²Œ ë°œê²¬ëœ ID: {len(diff_ids)}ê°œ")

    if not diff_ids:
        log("âœ… ìƒˆë¡œìš´ ê³µì—° ì—†ìŒ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    log("\nğŸ“‹ ê³µì—° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    dataset = build_performance_dataset(list(diff_ids))

    today = datetime.now().strftime("%Y%m%d")
    output_file = os.path.join(DATA_DIR, f"kopis_performances_{today}.json")
    save_json(dataset, output_file)

    updated_ids = existing_ids.union(new_ids)
    save_existing_ids(updated_ids, EXISTING_IDS_PATH)

    log(f"\nâœ… ì €ì¥ ì™„ë£Œ! ì´ {len(dataset)}ê°œ ê³µì—° ì •ë³´ â†’ {output_file}")
