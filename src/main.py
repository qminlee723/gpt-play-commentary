import json
from kopis_json_for_gpt import collect_unique_ids, build_performance_dataset
from utils import load_existing_ids, save_existing_ids
from datetiem import datetime, timedelta

def main():
    yesterday = datetime.today() - timedelta(days=1)
    date_str = yesterday.strftime("%Y%m%d")  # ì˜ˆ: '20250420'

    start_date = date_str
    end_date = date_str

    print("ğŸ¬ ê³µì—° ID ìˆ˜ì§‘ ì‹œì‘...")
    new_ids = collect_unique_ids(start_date, end_date)

    print("\nğŸ“ ê¸°ì¡´ ID ë¡œë”© ì¤‘...")
    existing_ids = load_existing_ids()

    print(f"ğŸ” ê¸°ì¡´: {len(existing_ids)}ê°œ, ì´ë²ˆ ìˆ˜ì§‘: {len(new_ids)}ê°œ")
    diff_ids = new_ids - existing_ids
    print(f"âœ¨ ìƒˆë¡­ê²Œ ë°œê²¬ëœ ID: {len(diff_ids)}ê°œ")

    if not diff_ids:
        print("âœ… ìƒˆë¡œìš´ ê³µì—° ì—†ìŒ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print("\nğŸ“‹ ê³µì—° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    dataset = build_performance_dataset(list(diff_ids))

    output_file = "kopis_performances_new.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)

    # ê¸°ì¡´ ID ì—…ë°ì´íŠ¸
    updated_ids = existing_ids.union(new_ids)
    save_existing_ids(updated_ids)

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ! ì´ {len(dataset)}ê°œ ê³µì—° ì •ë³´ â†’ {output_file}")


if __name__ == "__main__":
    main()
